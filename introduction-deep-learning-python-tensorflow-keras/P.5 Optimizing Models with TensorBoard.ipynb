{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to part 5 of the Deep learning with Python, TensorFlow and Keras tutorial series. In the previous tutorial, we introduced TensorBoard, which is an application that we can use to visualize our model's training stats over time. In this tutorial, we're going to continue on that to exemplify how you might build a workflow to optimize your model's architecture.\n",
    "\n",
    "To begin, let's think of a few things we could do to this model that we'd like to know.\n",
    "\n",
    "The most basic things for us to modify are layers and nodes per layer, as well as 0, 1, or 2 dense layers. Let's test those things. How might we do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-conv-32-nodes-0-dense-1542608880\n",
      "2-conv-32-nodes-0-dense-1542608880\n",
      "3-conv-32-nodes-0-dense-1542608880\n",
      "1-conv-64-nodes-0-dense-1542608880\n",
      "2-conv-64-nodes-0-dense-1542608880\n",
      "3-conv-64-nodes-0-dense-1542608880\n",
      "1-conv-128-nodes-0-dense-1542608880\n",
      "2-conv-128-nodes-0-dense-1542608880\n",
      "3-conv-128-nodes-0-dense-1542608880\n",
      "1-conv-32-nodes-1-dense-1542608880\n",
      "2-conv-32-nodes-1-dense-1542608880\n",
      "3-conv-32-nodes-1-dense-1542608880\n",
      "1-conv-64-nodes-1-dense-1542608880\n",
      "2-conv-64-nodes-1-dense-1542608880\n",
      "3-conv-64-nodes-1-dense-1542608880\n",
      "1-conv-128-nodes-1-dense-1542608880\n",
      "2-conv-128-nodes-1-dense-1542608880\n",
      "3-conv-128-nodes-1-dense-1542608880\n",
      "1-conv-32-nodes-2-dense-1542608880\n",
      "2-conv-32-nodes-2-dense-1542608880\n",
      "3-conv-32-nodes-2-dense-1542608880\n",
      "1-conv-64-nodes-2-dense-1542608880\n",
      "2-conv-64-nodes-2-dense-1542608880\n",
      "3-conv-64-nodes-2-dense-1542608880\n",
      "1-conv-128-nodes-2-dense-1542608880\n",
      "2-conv-128-nodes-2-dense-1542608880\n",
      "3-conv-128-nodes-2-dense-1542608880\n"
     ]
    }
   ],
   "source": [
    "# A simple for-loop will do! For example:\n",
    "\n",
    "import time\n",
    "\n",
    "dense_layers = [0,1,2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's a lot of combinations. I will be running them all, you don't have to. If you have a decent GPU, you can install and use Tensorflow-GPU instead. If you want to learn how to do that, I have two tutorials doing it:\n",
    "\n",
    "TensorFlow-GPU on Ubuntu\n",
    "TensorFlow-GPU on Windows\n",
    "Both videos are for an older version of TF, but the methodology for getting Tensorflow-GPU is fairly straight forward. You do a pip install tensorflow-gpu, then download the Cuda Toolkit, and then CuDNN. Install Cuda Toolkit, and copy the files over from CuDNN to the toolkit. Check out the videos above for more help on this, however. Also make sure you grab the right versions of Cuda Toolkit and CuDNN. See the installation docs on Tensorflow.org for your operating system to get the version #s you need!\n",
    "\n",
    "You can also use GPUs in the cloud. I recommend Paperspace for this, and I covered using them in this video\n",
    "\n",
    "Anywho, let's build the model next.\n",
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]\n",
    "\n",
    "    for dense_layer in dense_layers:\n",
    "        for layer_size in layer_sizes:\n",
    "            for conv_layer in conv_layers:\n",
    "                NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "                print(NAME)\n",
    "\n",
    "                model = Sequential()\n",
    "\n",
    "                model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "                for l in range(conv_layer-1):\n",
    "                    model.add(Conv2D(layer_size, (3, 3)))\n",
    "                    model.add(Activation('relu'))\n",
    "                    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "                model.add(Flatten())\n",
    "                for _ in range(dense_layer):\n",
    "                    model.add(Dense(layer_size))\n",
    "                    model.add(Activation('relu'))\n",
    "\n",
    "                model.add(Dense(1))\n",
    "                model.add(Activation('sigmoid'))\n",
    "                \n",
    "Even just toying with these parameters will take some significant time. We haven't even begun to touch other concepts like varying layer sizes, activation functions, learning rates, dropouts, and much much more.\n",
    "\n",
    "In general, I try to test only a few things. You almost want to make a hill-climb operation out of this process. First find a model that works. On this dataset, that part was easy. Then try to tinker with 2 or 3 things max. If there's a long/infinite list of options, such as is the case with layer count and nodes per layer, try to just do maybe one move in each direction.\n",
    "\n",
    "For example, if you find a 64 node-per-layer is working. Try a 32 and a 128, along with 64, so your list is [32, 64, 128]. If 128 shows better results, then maybe try [64, 128, 256] next, and so on.\n",
    "\n",
    "Just note that, as you change certain parameters, you may need to revisit older ones. As you tweak dropout, for example, let's say you add or just increase dropout. As you add or increase dropout, you can likely have a larger overall model in terms of layers or nodes per layer than before. A larger model overall might want a larger starting learning rate or a slower rate of decay for the learning rate.\n",
    "\n",
    "Finally, take note that there is some randomness in models. No two rounds of optimizations will be identical. They should be close, but not identical. Models are also initialized with random weights. This can impact models fairly significantly, especially in shorter numbers of epochs or if you have a small training set.\n",
    "\n",
    "Anyway, here's the full script for initial model testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-conv-32-nodes-0-dense-1542609160\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 3s 167us/step - loss: 0.6367 - acc: 0.6352 - val_loss: 0.5891 - val_acc: 0.6958\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 2s 127us/step - loss: 0.5701 - acc: 0.7087 - val_loss: 0.5677 - val_acc: 0.7092\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 2s 129us/step - loss: 0.5323 - acc: 0.7356 - val_loss: 0.5550 - val_acc: 0.7179\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 2s 132us/step - loss: 0.5122 - acc: 0.7557 - val_loss: 0.5618 - val_acc: 0.7108\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 2s 130us/step - loss: 0.4896 - acc: 0.7704 - val_loss: 0.5265 - val_acc: 0.7399\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 2s 129us/step - loss: 0.4746 - acc: 0.7785 - val_loss: 0.5203 - val_acc: 0.7434\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 2s 129us/step - loss: 0.4605 - acc: 0.7879 - val_loss: 0.5254 - val_acc: 0.7403\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 2s 127us/step - loss: 0.4511 - acc: 0.7920 - val_loss: 0.5281 - val_acc: 0.7422\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 2s 133us/step - loss: 0.4378 - acc: 0.8000 - val_loss: 0.5233 - val_acc: 0.7426\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 2s 133us/step - loss: 0.4301 - acc: 0.8072 - val_loss: 0.5619 - val_acc: 0.7235\n",
      "2-conv-32-nodes-0-dense-1542609184\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 3s 166us/step - loss: 0.6367 - acc: 0.6238 - val_loss: 0.5716 - val_acc: 0.7089\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 3s 159us/step - loss: 0.5500 - acc: 0.7236 - val_loss: 0.5248 - val_acc: 0.7406\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 3s 167us/step - loss: 0.5104 - acc: 0.7524 - val_loss: 0.5003 - val_acc: 0.7530\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 3s 161us/step - loss: 0.4885 - acc: 0.7649 - val_loss: 0.5055 - val_acc: 0.7497\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 3s 158us/step - loss: 0.4676 - acc: 0.7835 - val_loss: 0.5043 - val_acc: 0.7576\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 3s 166us/step - loss: 0.4543 - acc: 0.7898 - val_loss: 0.4902 - val_acc: 0.7678\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 3s 170us/step - loss: 0.4391 - acc: 0.7997 - val_loss: 0.4827 - val_acc: 0.7691\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 3s 167us/step - loss: 0.4222 - acc: 0.8104 - val_loss: 0.4754 - val_acc: 0.7759\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 3s 166us/step - loss: 0.4117 - acc: 0.8130 - val_loss: 0.4792 - val_acc: 0.7765\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 3s 160us/step - loss: 0.3998 - acc: 0.8189 - val_loss: 0.4695 - val_acc: 0.7785\n",
      "3-conv-32-nodes-0-dense-1542609213\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 3s 180us/step - loss: 0.6539 - acc: 0.6091 - val_loss: 0.6065 - val_acc: 0.6698\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 3s 169us/step - loss: 0.5860 - acc: 0.6918 - val_loss: 0.5730 - val_acc: 0.7006\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 3s 172us/step - loss: 0.5392 - acc: 0.7331 - val_loss: 0.5149 - val_acc: 0.7485\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 3s 177us/step - loss: 0.5098 - acc: 0.7542 - val_loss: 0.5497 - val_acc: 0.7247\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 3s 177us/step - loss: 0.4825 - acc: 0.7680 - val_loss: 0.4757 - val_acc: 0.7762\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 3s 179us/step - loss: 0.4613 - acc: 0.7824 - val_loss: 0.5454 - val_acc: 0.7387\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 3s 189us/step - loss: 0.4391 - acc: 0.7992 - val_loss: 0.4926 - val_acc: 0.7583\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 3s 185us/step - loss: 0.4214 - acc: 0.8067 - val_loss: 0.5547 - val_acc: 0.7237\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 3s 171us/step - loss: 0.4005 - acc: 0.8174 - val_loss: 0.4626 - val_acc: 0.7837\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 3s 170us/step - loss: 0.3848 - acc: 0.8249 - val_loss: 0.4751 - val_acc: 0.7814\n",
      "1-conv-64-nodes-0-dense-1542609245\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 4s 224us/step - loss: 0.6288 - acc: 0.6454 - val_loss: 0.5749 - val_acc: 0.7090\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 4s 217us/step - loss: 0.5533 - acc: 0.7195 - val_loss: 0.5508 - val_acc: 0.7237\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 4s 213us/step - loss: 0.5222 - acc: 0.7469 - val_loss: 0.5426 - val_acc: 0.7286\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 4s 215us/step - loss: 0.4905 - acc: 0.7654 - val_loss: 0.5600 - val_acc: 0.7168\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 4s 215us/step - loss: 0.4694 - acc: 0.7790 - val_loss: 0.5257 - val_acc: 0.7427\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 4s 220us/step - loss: 0.4495 - acc: 0.7922 - val_loss: 0.5518 - val_acc: 0.7263\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 4s 215us/step - loss: 0.4347 - acc: 0.8013 - val_loss: 0.5338 - val_acc: 0.7422\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 4s 213us/step - loss: 0.4185 - acc: 0.8088 - val_loss: 0.5295 - val_acc: 0.7441\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 4s 211us/step - loss: 0.4010 - acc: 0.8192 - val_loss: 0.5419 - val_acc: 0.7413\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 4s 215us/step - loss: 0.3863 - acc: 0.8291 - val_loss: 0.5461 - val_acc: 0.7401\n",
      "2-conv-64-nodes-0-dense-1542609283\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 5s 297us/step - loss: 0.6268 - acc: 0.6431 - val_loss: 0.5552 - val_acc: 0.7221\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 5s 284us/step - loss: 0.5406 - acc: 0.7287 - val_loss: 0.5128 - val_acc: 0.7529\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 5s 289us/step - loss: 0.4991 - acc: 0.7609 - val_loss: 0.5190 - val_acc: 0.7462\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 5s 287us/step - loss: 0.4709 - acc: 0.7764 - val_loss: 0.5351 - val_acc: 0.7302\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 5s 289us/step - loss: 0.4511 - acc: 0.7899 - val_loss: 0.4556 - val_acc: 0.7908\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 5s 285us/step - loss: 0.4258 - acc: 0.8072 - val_loss: 0.4900 - val_acc: 0.7660\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 5s 281us/step - loss: 0.4233 - acc: 0.8072 - val_loss: 0.5078 - val_acc: 0.7530\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 5s 291us/step - loss: 0.3938 - acc: 0.8228 - val_loss: 0.4775 - val_acc: 0.7794\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 5s 290us/step - loss: 0.3780 - acc: 0.8315 - val_loss: 0.4408 - val_acc: 0.7976\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 5s 283us/step - loss: 0.3604 - acc: 0.8400 - val_loss: 0.4524 - val_acc: 0.7946\n",
      "3-conv-64-nodes-0-dense-1542609334\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 6s 317us/step - loss: 0.6528 - acc: 0.6035 - val_loss: 0.5994 - val_acc: 0.6812\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 5s 306us/step - loss: 0.5496 - acc: 0.7220 - val_loss: 0.5701 - val_acc: 0.7021\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 5s 308us/step - loss: 0.4948 - acc: 0.7615 - val_loss: 0.5204 - val_acc: 0.7374\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 5s 305us/step - loss: 0.4573 - acc: 0.7847 - val_loss: 0.4900 - val_acc: 0.7679\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 5s 304us/step - loss: 0.4328 - acc: 0.7979 - val_loss: 0.4821 - val_acc: 0.7652\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17441/17441 [==============================] - 6s 316us/step - loss: 0.3947 - acc: 0.8206 - val_loss: 0.4817 - val_acc: 0.7706\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 6s 327us/step - loss: 0.3730 - acc: 0.8334 - val_loss: 0.4486 - val_acc: 0.7862\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 6s 335us/step - loss: 0.3513 - acc: 0.8434 - val_loss: 0.4231 - val_acc: 0.8043\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 6s 327us/step - loss: 0.3249 - acc: 0.8558 - val_loss: 0.4930 - val_acc: 0.7664\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 6s 330us/step - loss: 0.3047 - acc: 0.8660 - val_loss: 0.4223 - val_acc: 0.8111\n",
      "1-conv-128-nodes-0-dense-1542609390\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 7s 401us/step - loss: 0.6181 - acc: 0.6578 - val_loss: 0.5779 - val_acc: 0.7064\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 7s 392us/step - loss: 0.5445 - acc: 0.7325 - val_loss: 0.5617 - val_acc: 0.7050\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 7s 395us/step - loss: 0.5116 - acc: 0.7524 - val_loss: 0.5620 - val_acc: 0.7120\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 7s 397us/step - loss: 0.4882 - acc: 0.7700 - val_loss: 0.5420 - val_acc: 0.7302\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 7s 398us/step - loss: 0.4585 - acc: 0.7854 - val_loss: 0.5227 - val_acc: 0.7458\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 7s 391us/step - loss: 0.4336 - acc: 0.8000 - val_loss: 0.5338 - val_acc: 0.7382\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 7s 386us/step - loss: 0.4130 - acc: 0.8102 - val_loss: 0.5390 - val_acc: 0.7407\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 7s 409us/step - loss: 0.3929 - acc: 0.8236 - val_loss: 0.5602 - val_acc: 0.7330\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 7s 393us/step - loss: 0.3709 - acc: 0.8366 - val_loss: 0.5483 - val_acc: 0.7447\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 7s 395us/step - loss: 0.3521 - acc: 0.8469 - val_loss: 0.5561 - val_acc: 0.7377\n",
      "2-conv-128-nodes-0-dense-1542609460\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 10s 569us/step - loss: 0.6316 - acc: 0.6349 - val_loss: 0.5897 - val_acc: 0.6828\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 10s 559us/step - loss: 0.5423 - acc: 0.7296 - val_loss: 0.5126 - val_acc: 0.7485\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 10s 553us/step - loss: 0.4954 - acc: 0.7627 - val_loss: 0.4937 - val_acc: 0.7573\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 10s 554us/step - loss: 0.4575 - acc: 0.7857 - val_loss: 0.4879 - val_acc: 0.7687\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 10s 554us/step - loss: 0.4289 - acc: 0.8026 - val_loss: 0.4680 - val_acc: 0.7821\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 10s 561us/step - loss: 0.4044 - acc: 0.8174 - val_loss: 0.4580 - val_acc: 0.7873\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 9s 542us/step - loss: 0.3733 - acc: 0.8314 - val_loss: 0.4873 - val_acc: 0.7748\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 9s 538us/step - loss: 0.3536 - acc: 0.8436 - val_loss: 0.4621 - val_acc: 0.7925\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 10s 546us/step - loss: 0.3322 - acc: 0.8552 - val_loss: 0.4927 - val_acc: 0.7765\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 9s 538us/step - loss: 0.3248 - acc: 0.8574 - val_loss: 0.4781 - val_acc: 0.7925\n",
      "3-conv-128-nodes-0-dense-1542609557\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 11s 612us/step - loss: 0.6508 - acc: 0.6116 - val_loss: 0.5822 - val_acc: 0.6942\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 10s 598us/step - loss: 0.5539 - acc: 0.7199 - val_loss: 0.5365 - val_acc: 0.7304\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 10s 594us/step - loss: 0.4896 - acc: 0.7653 - val_loss: 0.4790 - val_acc: 0.7720\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 10s 598us/step - loss: 0.4337 - acc: 0.8001 - val_loss: 0.4735 - val_acc: 0.7771\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 10s 597us/step - loss: 0.3933 - acc: 0.8220 - val_loss: 0.4437 - val_acc: 0.7920\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 10s 598us/step - loss: 0.3589 - acc: 0.8394 - val_loss: 0.4226 - val_acc: 0.8100\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 10s 598us/step - loss: 0.3196 - acc: 0.8596 - val_loss: 0.4228 - val_acc: 0.8190\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 10s 595us/step - loss: 0.2896 - acc: 0.8732 - val_loss: 0.4341 - val_acc: 0.8092\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 10s 592us/step - loss: 0.2545 - acc: 0.8909 - val_loss: 0.4454 - val_acc: 0.8108\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 10s 594us/step - loss: 0.2231 - acc: 0.9070 - val_loss: 0.4725 - val_acc: 0.8044\n",
      "1-conv-32-nodes-1-dense-1542609662\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 3s 176us/step - loss: 0.6261 - acc: 0.6407 - val_loss: 0.5829 - val_acc: 0.6890\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 3s 167us/step - loss: 0.5385 - acc: 0.7307 - val_loss: 0.5389 - val_acc: 0.7327\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 3s 168us/step - loss: 0.4970 - acc: 0.7638 - val_loss: 0.5275 - val_acc: 0.7422\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 3s 170us/step - loss: 0.4625 - acc: 0.7849 - val_loss: 0.5484 - val_acc: 0.7311\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 3s 168us/step - loss: 0.4296 - acc: 0.8010 - val_loss: 0.5402 - val_acc: 0.7379\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 3s 167us/step - loss: 0.3969 - acc: 0.8205 - val_loss: 0.5387 - val_acc: 0.7415\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 3s 178us/step - loss: 0.3580 - acc: 0.8416 - val_loss: 0.5897 - val_acc: 0.7255\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 3s 166us/step - loss: 0.3271 - acc: 0.8608 - val_loss: 0.6329 - val_acc: 0.7252\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 3s 169us/step - loss: 0.2849 - acc: 0.8817 - val_loss: 0.6078 - val_acc: 0.7362\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 3s 168us/step - loss: 0.2490 - acc: 0.9008 - val_loss: 0.6439 - val_acc: 0.7369\n",
      "2-conv-32-nodes-1-dense-1542609693\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 3s 183us/step - loss: 0.6289 - acc: 0.6380 - val_loss: 0.5484 - val_acc: 0.7215\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 3s 172us/step - loss: 0.5348 - acc: 0.7356 - val_loss: 0.5088 - val_acc: 0.7464\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 3s 174us/step - loss: 0.4905 - acc: 0.7644 - val_loss: 0.4889 - val_acc: 0.7641\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 3s 176us/step - loss: 0.4617 - acc: 0.7875 - val_loss: 0.4729 - val_acc: 0.7726\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 3s 171us/step - loss: 0.4341 - acc: 0.8025 - val_loss: 0.4621 - val_acc: 0.7814\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 3s 174us/step - loss: 0.4121 - acc: 0.8092 - val_loss: 0.4578 - val_acc: 0.7865\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 3s 175us/step - loss: 0.3851 - acc: 0.8284 - val_loss: 0.4704 - val_acc: 0.7837\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 3s 176us/step - loss: 0.3649 - acc: 0.8372 - val_loss: 0.5334 - val_acc: 0.7524\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 3s 171us/step - loss: 0.3449 - acc: 0.8479 - val_loss: 0.4619 - val_acc: 0.7865\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 3s 177us/step - loss: 0.3211 - acc: 0.8571 - val_loss: 0.4754 - val_acc: 0.7857\n",
      "3-conv-32-nodes-1-dense-1542609724\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17441/17441 [==============================] - 4s 201us/step - loss: 0.6653 - acc: 0.5897 - val_loss: 0.6495 - val_acc: 0.6142\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 3s 189us/step - loss: 0.5932 - acc: 0.6826 - val_loss: 0.5864 - val_acc: 0.7050\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 3s 185us/step - loss: 0.5316 - acc: 0.7316 - val_loss: 0.5132 - val_acc: 0.7454\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 3s 183us/step - loss: 0.4874 - acc: 0.7624 - val_loss: 0.4885 - val_acc: 0.7637\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 3s 184us/step - loss: 0.4524 - acc: 0.7828 - val_loss: 0.4690 - val_acc: 0.7767\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 3s 193us/step - loss: 0.4202 - acc: 0.8039 - val_loss: 0.4957 - val_acc: 0.7624\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 3s 194us/step - loss: 0.3937 - acc: 0.8224 - val_loss: 0.4487 - val_acc: 0.7914\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 3s 179us/step - loss: 0.3716 - acc: 0.8321 - val_loss: 0.4989 - val_acc: 0.7806\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 3s 185us/step - loss: 0.3497 - acc: 0.8444 - val_loss: 0.4468 - val_acc: 0.7969\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 3s 192us/step - loss: 0.3315 - acc: 0.8536 - val_loss: 0.4442 - val_acc: 0.8000\n",
      "1-conv-64-nodes-1-dense-1542609758\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 6s 366us/step - loss: 0.6126 - acc: 0.6650 - val_loss: 0.5569 - val_acc: 0.7213\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 6s 354us/step - loss: 0.5249 - acc: 0.7415 - val_loss: 0.6157 - val_acc: 0.6760\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 6s 358us/step - loss: 0.4804 - acc: 0.7720 - val_loss: 0.5201 - val_acc: 0.7466\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 6s 359us/step - loss: 0.4272 - acc: 0.8038 - val_loss: 0.5248 - val_acc: 0.7410\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 6s 353us/step - loss: 0.3813 - acc: 0.8279 - val_loss: 0.5343 - val_acc: 0.7470\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 6s 357us/step - loss: 0.3118 - acc: 0.8658 - val_loss: 0.5758 - val_acc: 0.7386\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 6s 351us/step - loss: 0.2431 - acc: 0.9013 - val_loss: 0.6377 - val_acc: 0.7386\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 6s 347us/step - loss: 0.1771 - acc: 0.9323 - val_loss: 0.6776 - val_acc: 0.7362\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 6s 348us/step - loss: 0.1256 - acc: 0.9574 - val_loss: 0.8180 - val_acc: 0.7335\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 6s 355us/step - loss: 0.0782 - acc: 0.9776 - val_loss: 0.8540 - val_acc: 0.7332\n",
      "2-conv-64-nodes-1-dense-1542609821\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 6s 363us/step - loss: 0.6434 - acc: 0.6110 - val_loss: 0.5910 - val_acc: 0.6895\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 6s 334us/step - loss: 0.5346 - acc: 0.7359 - val_loss: 0.5766 - val_acc: 0.7010\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 6s 326us/step - loss: 0.5000 - acc: 0.7574 - val_loss: 0.5039 - val_acc: 0.7526\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 6s 321us/step - loss: 0.4565 - acc: 0.7883 - val_loss: 0.4821 - val_acc: 0.7648\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 6s 331us/step - loss: 0.4252 - acc: 0.8059 - val_loss: 0.4911 - val_acc: 0.7654\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 6s 319us/step - loss: 0.3973 - acc: 0.8189 - val_loss: 0.5053 - val_acc: 0.7565\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 6s 332us/step - loss: 0.3545 - acc: 0.8415 - val_loss: 0.4860 - val_acc: 0.7787\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 6s 330us/step - loss: 0.3222 - acc: 0.8580 - val_loss: 0.5189 - val_acc: 0.7805\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 6s 331us/step - loss: 0.2844 - acc: 0.8772 - val_loss: 0.4940 - val_acc: 0.7870\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 6s 326us/step - loss: 0.2473 - acc: 0.8951 - val_loss: 0.4958 - val_acc: 0.7912\n",
      "3-conv-64-nodes-1-dense-1542609881\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 6s 339us/step - loss: 0.6432 - acc: 0.6145 - val_loss: 0.5691 - val_acc: 0.7144\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 6s 318us/step - loss: 0.5408 - acc: 0.7274 - val_loss: 0.4977 - val_acc: 0.7640\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 6s 330us/step - loss: 0.4772 - acc: 0.7701 - val_loss: 0.4713 - val_acc: 0.7769\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 6s 336us/step - loss: 0.4211 - acc: 0.8061 - val_loss: 0.4968 - val_acc: 0.7660\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 6s 324us/step - loss: 0.3788 - acc: 0.8289 - val_loss: 0.4150 - val_acc: 0.8066\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 6s 323us/step - loss: 0.3424 - acc: 0.8462 - val_loss: 0.4125 - val_acc: 0.8179\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 6s 328us/step - loss: 0.3064 - acc: 0.8669 - val_loss: 0.4064 - val_acc: 0.8205\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 6s 319us/step - loss: 0.2767 - acc: 0.8817 - val_loss: 0.4636 - val_acc: 0.7987\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 6s 329us/step - loss: 0.2511 - acc: 0.8917 - val_loss: 0.5024 - val_acc: 0.8004\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 6s 334us/step - loss: 0.2076 - acc: 0.9157 - val_loss: 0.4675 - val_acc: 0.8092\n",
      "1-conv-128-nodes-1-dense-1542609939\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 15s 874us/step - loss: 0.6093 - acc: 0.6703 - val_loss: 0.5475 - val_acc: 0.7251\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 15s 860us/step - loss: 0.5168 - acc: 0.7434 - val_loss: 0.5457 - val_acc: 0.7299\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 15s 861us/step - loss: 0.4648 - acc: 0.7772 - val_loss: 0.5598 - val_acc: 0.7192\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 15s 860us/step - loss: 0.4011 - acc: 0.8124 - val_loss: 0.5299 - val_acc: 0.7433\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 15s 861us/step - loss: 0.3193 - acc: 0.8602 - val_loss: 0.5645 - val_acc: 0.7366\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 15s 861us/step - loss: 0.2290 - acc: 0.9087 - val_loss: 0.6820 - val_acc: 0.7264\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 15s 862us/step - loss: 0.1529 - acc: 0.9423 - val_loss: 0.7906 - val_acc: 0.7275\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 15s 861us/step - loss: 0.0865 - acc: 0.9715 - val_loss: 0.8812 - val_acc: 0.7363\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 15s 863us/step - loss: 0.0422 - acc: 0.9896 - val_loss: 1.0585 - val_acc: 0.7192\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 15s 865us/step - loss: 0.0254 - acc: 0.9944 - val_loss: 1.1383 - val_acc: 0.7346\n",
      "2-conv-128-nodes-1-dense-1542610091\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 11s 645us/step - loss: 0.6595 - acc: 0.5954 - val_loss: 0.5989 - val_acc: 0.6977\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 11s 635us/step - loss: 0.5559 - acc: 0.7161 - val_loss: 0.5182 - val_acc: 0.7489\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 11s 634us/step - loss: 0.4996 - acc: 0.7578 - val_loss: 0.5241 - val_acc: 0.7446\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 11s 634us/step - loss: 0.4625 - acc: 0.7838 - val_loss: 0.4909 - val_acc: 0.7601\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 11s 632us/step - loss: 0.4247 - acc: 0.8045 - val_loss: 0.4784 - val_acc: 0.7722\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 11s 634us/step - loss: 0.3834 - acc: 0.8248 - val_loss: 0.4795 - val_acc: 0.7831\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17441/17441 [==============================] - 11s 640us/step - loss: 0.3436 - acc: 0.8476 - val_loss: 0.4666 - val_acc: 0.7894\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 11s 640us/step - loss: 0.3049 - acc: 0.8659 - val_loss: 0.5030 - val_acc: 0.7825\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 11s 642us/step - loss: 0.2463 - acc: 0.8996 - val_loss: 0.5380 - val_acc: 0.7853\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 11s 639us/step - loss: 0.1905 - acc: 0.9243 - val_loss: 0.5808 - val_acc: 0.7797\n",
      "3-conv-128-nodes-1-dense-1542610204\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 11s 644us/step - loss: 0.6371 - acc: 0.6268 - val_loss: 0.5608 - val_acc: 0.7129\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 11s 626us/step - loss: 0.5261 - acc: 0.7420 - val_loss: 0.5070 - val_acc: 0.7513\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 11s 630us/step - loss: 0.4503 - acc: 0.7877 - val_loss: 0.4533 - val_acc: 0.7897\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 11s 625us/step - loss: 0.3952 - acc: 0.8208 - val_loss: 0.4192 - val_acc: 0.8062\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 11s 621us/step - loss: 0.3472 - acc: 0.8461 - val_loss: 0.4172 - val_acc: 0.8154\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 11s 627us/step - loss: 0.2998 - acc: 0.8689 - val_loss: 0.4289 - val_acc: 0.8155\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 11s 625us/step - loss: 0.2643 - acc: 0.8840 - val_loss: 0.4205 - val_acc: 0.8211\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 11s 622us/step - loss: 0.2122 - acc: 0.9124 - val_loss: 0.4880 - val_acc: 0.8054\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 11s 623us/step - loss: 0.1765 - acc: 0.9296 - val_loss: 0.5201 - val_acc: 0.8031\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 11s 621us/step - loss: 0.1883 - acc: 0.9221 - val_loss: 0.5661 - val_acc: 0.8162\n",
      "1-conv-32-nodes-2-dense-1542610315\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 3s 189us/step - loss: 0.6366 - acc: 0.6330 - val_loss: 0.5679 - val_acc: 0.7124\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 3s 182us/step - loss: 0.5437 - acc: 0.7294 - val_loss: 0.5585 - val_acc: 0.7168\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 3s 175us/step - loss: 0.4946 - acc: 0.7625 - val_loss: 0.5298 - val_acc: 0.7398\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 3s 174us/step - loss: 0.4485 - acc: 0.7928 - val_loss: 0.5883 - val_acc: 0.7205\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 3s 179us/step - loss: 0.4242 - acc: 0.8052 - val_loss: 0.5355 - val_acc: 0.7385\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 3s 175us/step - loss: 0.3745 - acc: 0.8329 - val_loss: 0.5734 - val_acc: 0.7381\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 3s 179us/step - loss: 0.3245 - acc: 0.8572 - val_loss: 0.6143 - val_acc: 0.7402\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 3s 189us/step - loss: 0.2730 - acc: 0.8818 - val_loss: 0.6275 - val_acc: 0.7314\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 3s 179us/step - loss: 0.2246 - acc: 0.9060 - val_loss: 0.7518 - val_acc: 0.7279\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 3s 183us/step - loss: 0.1781 - acc: 0.9291 - val_loss: 0.8015 - val_acc: 0.7209\n",
      "2-conv-32-nodes-2-dense-1542610348\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 4s 202us/step - loss: 0.6468 - acc: 0.6108 - val_loss: 0.5789 - val_acc: 0.7041\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 3s 188us/step - loss: 0.5437 - acc: 0.7282 - val_loss: 0.5035 - val_acc: 0.7530\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 3s 185us/step - loss: 0.4911 - acc: 0.7641 - val_loss: 0.4913 - val_acc: 0.7621\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 3s 190us/step - loss: 0.4605 - acc: 0.7833 - val_loss: 0.5100 - val_acc: 0.7508\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 3s 185us/step - loss: 0.4289 - acc: 0.8020 - val_loss: 0.4836 - val_acc: 0.7703\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 3s 186us/step - loss: 0.3995 - acc: 0.8190 - val_loss: 0.4705 - val_acc: 0.7763\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 3s 184us/step - loss: 0.3674 - acc: 0.8375 - val_loss: 0.5244 - val_acc: 0.7605\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 3s 179us/step - loss: 0.3352 - acc: 0.8516 - val_loss: 0.4857 - val_acc: 0.7827\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 3s 195us/step - loss: 0.2955 - acc: 0.8724 - val_loss: 0.5003 - val_acc: 0.7842\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 4s 207us/step - loss: 0.2688 - acc: 0.8856 - val_loss: 0.5448 - val_acc: 0.7874\n",
      "3-conv-32-nodes-2-dense-1542610383\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 4s 228us/step - loss: 0.6594 - acc: 0.5912 - val_loss: 0.6290 - val_acc: 0.6496\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 3s 187us/step - loss: 0.5668 - acc: 0.7056 - val_loss: 0.5507 - val_acc: 0.7155\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 3s 190us/step - loss: 0.5074 - acc: 0.7528 - val_loss: 0.5015 - val_acc: 0.7537\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 3s 197us/step - loss: 0.4707 - acc: 0.7748 - val_loss: 0.4784 - val_acc: 0.7722\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 3s 193us/step - loss: 0.4389 - acc: 0.7932 - val_loss: 0.4506 - val_acc: 0.7865\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 3s 190us/step - loss: 0.4090 - acc: 0.8129 - val_loss: 0.4559 - val_acc: 0.7906\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 4s 206us/step - loss: 0.3781 - acc: 0.8310 - val_loss: 0.5352 - val_acc: 0.7493\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 4s 201us/step - loss: 0.3610 - acc: 0.8400 - val_loss: 0.4379 - val_acc: 0.7999\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 3s 190us/step - loss: 0.3433 - acc: 0.8487 - val_loss: 0.4593 - val_acc: 0.7968\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 3s 191us/step - loss: 0.3140 - acc: 0.8637 - val_loss: 0.4638 - val_acc: 0.7948\n",
      "1-conv-64-nodes-2-dense-1542610420\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 6s 371us/step - loss: 0.6053 - acc: 0.6711 - val_loss: 0.5418 - val_acc: 0.7237\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 6s 353us/step - loss: 0.5092 - acc: 0.7520 - val_loss: 0.5722 - val_acc: 0.7069\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 6s 354us/step - loss: 0.4421 - acc: 0.7943 - val_loss: 0.5290 - val_acc: 0.7434\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 6s 357us/step - loss: 0.3577 - acc: 0.8388 - val_loss: 0.5593 - val_acc: 0.7445\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 6s 356us/step - loss: 0.2643 - acc: 0.8895 - val_loss: 0.6569 - val_acc: 0.7227\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 6s 356us/step - loss: 0.1678 - acc: 0.9346 - val_loss: 0.7966 - val_acc: 0.7308\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 6s 352us/step - loss: 0.1024 - acc: 0.9608 - val_loss: 1.0658 - val_acc: 0.7300\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 6s 353us/step - loss: 0.0664 - acc: 0.9760 - val_loss: 1.2019 - val_acc: 0.7256\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 6s 351us/step - loss: 0.0488 - acc: 0.9830 - val_loss: 1.4760 - val_acc: 0.6944\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 6s 356us/step - loss: 0.0628 - acc: 0.9793 - val_loss: 1.4600 - val_acc: 0.7156\n",
      "2-conv-64-nodes-2-dense-1542610484\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 6s 352us/step - loss: 0.6147 - acc: 0.6531 - val_loss: 0.5368 - val_acc: 0.7295\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17441/17441 [==============================] - 6s 353us/step - loss: 0.5127 - acc: 0.7503 - val_loss: 0.4983 - val_acc: 0.7609\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 6s 364us/step - loss: 0.4662 - acc: 0.7795 - val_loss: 0.4818 - val_acc: 0.7684\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 6s 356us/step - loss: 0.4266 - acc: 0.8025 - val_loss: 0.5954 - val_acc: 0.7302\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 6s 337us/step - loss: 0.3773 - acc: 0.8313 - val_loss: 0.4661 - val_acc: 0.7830\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 6s 360us/step - loss: 0.3263 - acc: 0.8526 - val_loss: 0.5348 - val_acc: 0.7790\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 6s 356us/step - loss: 0.2723 - acc: 0.8784 - val_loss: 0.5197 - val_acc: 0.7885\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 6s 346us/step - loss: 0.2134 - acc: 0.9111 - val_loss: 0.6153 - val_acc: 0.7591\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 6s 353us/step - loss: 0.1562 - acc: 0.9373 - val_loss: 0.7455 - val_acc: 0.7782\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 6s 343us/step - loss: 0.1104 - acc: 0.9578 - val_loss: 0.8426 - val_acc: 0.7750\n",
      "3-conv-64-nodes-2-dense-1542610547\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 6s 368us/step - loss: 0.6593 - acc: 0.5943 - val_loss: 0.5839 - val_acc: 0.7034\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 6s 347us/step - loss: 0.5453 - acc: 0.7206 - val_loss: 0.5556 - val_acc: 0.7120\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 6s 351us/step - loss: 0.4738 - acc: 0.7714 - val_loss: 0.4475 - val_acc: 0.7948\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 6s 351us/step - loss: 0.4249 - acc: 0.8031 - val_loss: 0.4312 - val_acc: 0.7968\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 6s 352us/step - loss: 0.3808 - acc: 0.8300 - val_loss: 0.4359 - val_acc: 0.7967\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 6s 340us/step - loss: 0.3441 - acc: 0.8489 - val_loss: 0.4376 - val_acc: 0.8019\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 6s 340us/step - loss: 0.3222 - acc: 0.8569 - val_loss: 0.4407 - val_acc: 0.8088\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 6s 351us/step - loss: 0.2705 - acc: 0.8844 - val_loss: 0.4421 - val_acc: 0.8003\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 6s 342us/step - loss: 0.2398 - acc: 0.8991 - val_loss: 0.4609 - val_acc: 0.8153\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 6s 344us/step - loss: 0.2080 - acc: 0.9139 - val_loss: 0.4955 - val_acc: 0.8080\n",
      "1-conv-128-nodes-2-dense-1542610610\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 16s 893us/step - loss: 0.6159 - acc: 0.6625 - val_loss: 0.5720 - val_acc: 0.7034\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 15s 873us/step - loss: 0.5203 - acc: 0.7429 - val_loss: 0.5843 - val_acc: 0.6891\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 15s 873us/step - loss: 0.4437 - acc: 0.7919 - val_loss: 0.5335 - val_acc: 0.7414\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 15s 873us/step - loss: 0.3548 - acc: 0.8414 - val_loss: 0.5733 - val_acc: 0.7385\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 15s 871us/step - loss: 0.2452 - acc: 0.8948 - val_loss: 0.6674 - val_acc: 0.7298\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 15s 872us/step - loss: 0.1416 - acc: 0.9450 - val_loss: 0.9208 - val_acc: 0.7179\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 15s 873us/step - loss: 0.0732 - acc: 0.9737 - val_loss: 1.2632 - val_acc: 0.7207\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 15s 872us/step - loss: 0.0553 - acc: 0.9812 - val_loss: 1.2486 - val_acc: 0.7303\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 15s 872us/step - loss: 0.0456 - acc: 0.9854 - val_loss: 1.4982 - val_acc: 0.7007\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 15s 873us/step - loss: 0.0357 - acc: 0.9890 - val_loss: 1.5541 - val_acc: 0.7207\n",
      "2-conv-128-nodes-2-dense-1542610765\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 12s 668us/step - loss: 0.6531 - acc: 0.5992 - val_loss: 0.6315 - val_acc: 0.6404\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 11s 649us/step - loss: 0.5643 - acc: 0.7066 - val_loss: 0.5415 - val_acc: 0.7298\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 11s 646us/step - loss: 0.4964 - acc: 0.7584 - val_loss: 0.4962 - val_acc: 0.7568\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 11s 642us/step - loss: 0.4508 - acc: 0.7891 - val_loss: 0.4760 - val_acc: 0.7781\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 11s 644us/step - loss: 0.3984 - acc: 0.8186 - val_loss: 0.4977 - val_acc: 0.7688\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 11s 654us/step - loss: 0.3456 - acc: 0.8448 - val_loss: 0.4750 - val_acc: 0.7809\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 11s 650us/step - loss: 0.2736 - acc: 0.8837 - val_loss: 0.6092 - val_acc: 0.7476\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 11s 646us/step - loss: 0.2166 - acc: 0.9111 - val_loss: 0.5812 - val_acc: 0.7810\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 11s 643us/step - loss: 0.1414 - acc: 0.9460 - val_loss: 0.7222 - val_acc: 0.7767\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 11s 645us/step - loss: 0.1097 - acc: 0.9583 - val_loss: 0.8775 - val_acc: 0.7750\n",
      "3-conv-128-nodes-2-dense-1542610881\n",
      "Train on 17441 samples, validate on 7475 samples\n",
      "Epoch 1/10\n",
      "17441/17441 [==============================] - 11s 654us/step - loss: 0.6808 - acc: 0.5500 - val_loss: 0.6751 - val_acc: 0.5898\n",
      "Epoch 2/10\n",
      "17441/17441 [==============================] - 11s 632us/step - loss: 0.6302 - acc: 0.6422 - val_loss: 0.6325 - val_acc: 0.6637\n",
      "Epoch 3/10\n",
      "17441/17441 [==============================] - 11s 626us/step - loss: 0.5431 - acc: 0.7239 - val_loss: 0.4984 - val_acc: 0.7552\n",
      "Epoch 4/10\n",
      "17441/17441 [==============================] - 11s 625us/step - loss: 0.4741 - acc: 0.7743 - val_loss: 0.4975 - val_acc: 0.7553\n",
      "Epoch 5/10\n",
      "17441/17441 [==============================] - 11s 628us/step - loss: 0.4375 - acc: 0.7965 - val_loss: 0.6266 - val_acc: 0.7340\n",
      "Epoch 6/10\n",
      "17441/17441 [==============================] - 11s 622us/step - loss: 0.3940 - acc: 0.8196 - val_loss: 0.4308 - val_acc: 0.8005\n",
      "Epoch 7/10\n",
      "17441/17441 [==============================] - 11s 624us/step - loss: 0.3547 - acc: 0.8400 - val_loss: 0.4252 - val_acc: 0.8054\n",
      "Epoch 8/10\n",
      "17441/17441 [==============================] - 11s 622us/step - loss: 0.3200 - acc: 0.8576 - val_loss: 0.4411 - val_acc: 0.7972\n",
      "Epoch 9/10\n",
      "17441/17441 [==============================] - 11s 620us/step - loss: 0.2796 - acc: 0.8786 - val_loss: 0.4460 - val_acc: 0.8094\n",
      "Epoch 10/10\n",
      "17441/17441 [==============================] - 11s 626us/step - loss: 0.2434 - acc: 0.8945 - val_loss: 0.4767 - val_acc: 0.8029\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          )\n",
    "\n",
    "            model.fit(X, y,\n",
    "                      batch_size=32,\n",
    "                      epochs=10,\n",
    "                      validation_split=0.3,\n",
    "                      callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It could be tempting to take the highest validation accuracy model, but I tend to instead go for the best (lowest) validation loss models. Like I said before, there is some randomness when it comes to models, but you should notice trends.\n",
    "\n",
    "For one, I notice that the models with 0 dense layers seemed to do better overall. There are some very successful models with dense layers, but I am going to guess one is likely not needed here.\n",
    "\n",
    "So, zooming into the validation accuracy graph, let's check some of the best ones. Here are the top 10:\n",
    "\n",
    "    3 conv, 64 nodes per layer, 0 dense\n",
    "    3 conv, 128 nodes per layer, 0 dense\n",
    "    3 conv, 32 nodes per layer, 0 dense\n",
    "    3 conv, 32 nodes per layer, 2 dense\n",
    "    3 conv, 32 nodes per layer, 1 dense\n",
    "    2 conv, 32 nodes per layer, 0 dense\n",
    "    2 conv, 64 nodes per layer, 0 dense\n",
    "    3 conv, 128 nodes per layer, 1 dense\n",
    "    2 conv, 128 nodes per layer, 0 dense\n",
    "    2 conv, 32 nodes per layer, 1 dense\n",
    "    \n",
    "From here, I think we can be comfortable with 0 dense, and 3 convolutional layers, since every version of those 2 options proved to be better than anything else. Just the top 3 models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
